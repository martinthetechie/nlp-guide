{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPPH7osyFs1l/Xoqn4oBIFu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martinthetechie/nlp-guide/blob/main/pos_tagging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quote = \"Happiness can be found, even in the darkest of times, if one only remembers to turn on the light.\"\n"
      ],
      "metadata": {
        "id": "Cubp0mwZbjXJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>NLTK Demo</h2>"
      ],
      "metadata": {
        "id": "fCQqD6MVjWrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tag import RegexpTagger\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Define patterns for rule-based tagging\n",
        "patterns = [\n",
        "    (r'^Happiness$', 'NOUN'),\n",
        "    (r'^can$', 'VERB'),\n",
        "    (r'^be$', 'VERB'),\n",
        "    (r'^found$', 'VERB'),\n",
        "    (r'^even$', 'ADV'),\n",
        "    (r'^in$', 'ADP'),\n",
        "    (r'^the$', 'DET'),\n",
        "    (r'^darkest$', 'ADJ'),\n",
        "    (r'^of$', 'ADP'),\n",
        "    (r'^times$', 'NOUN'),\n",
        "    (r'^if$', 'SCONJ'),\n",
        "    (r'^one$', 'PRON'),\n",
        "    (r'^only$', 'ADV'),\n",
        "    (r'^remembers$', 'VERB'),\n",
        "    (r'^to$', 'PART'),\n",
        "    (r'^turn$', 'VERB'),\n",
        "    (r'^on$', 'ADP'),\n",
        "    (r'^light$', 'NOUN'),\n",
        "    (r'^,$', 'PUNC'),\n",
        "    (r'^.$', 'PUNC'),\n",
        "]\n",
        "\n",
        "# Create a RegexpTagger with the defined patterns\n",
        "tagger = RegexpTagger(patterns)\n",
        "\n",
        "# Tokenize and apply rule-based tagging\n",
        "tokens = word_tokenize(quote)\n",
        "rule_based_tags = tagger.tag(tokens)\n",
        "\n",
        "word_dict = {word: tag for word, tag in rule_based_tags}\n",
        "print(word_dict)\n",
        "\n",
        "# {'Happiness': 'NOUN', 'can': 'VERB', 'be': 'VERB', 'found': 'VERB', ',': 'PUNC', 'even': 'ADV', 'in': 'ADP', 'the': 'DET', 'darkest': 'ADJ', 'of': 'ADP', 'times': 'NOUN', 'if': 'SCONJ', 'one': 'PRON', 'only': 'ADV', 'remembers': 'VERB', 'to': 'PART', 'turn': 'VERB', 'on': 'ADP', 'light': 'NOUN', '.': 'PUNC'}"
      ],
      "metadata": {
        "id": "8t3jtbqnbniK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96f78d44-f53b-4254-a7a3-caa331a05aec"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Happiness': 'NOUN', 'can': 'VERB', 'be': 'VERB', 'found': 'VERB', ',': 'PUNC', 'even': 'ADV', 'in': 'ADP', 'the': 'DET', 'darkest': 'ADJ', 'of': 'ADP', 'times': 'NOUN', 'if': 'SCONJ', 'one': 'PRON', 'only': 'ADV', 'remembers': 'VERB', 'to': 'PART', 'turn': 'VERB', 'on': 'ADP', 'light': 'NOUN', '.': 'PUNC'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "\n",
        "# nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Tokenize the sentence\n",
        "tokens = word_tokenize(quote)\n",
        "\n",
        "# Apply statistical POS tagging\n",
        "statistical_tags = pos_tag(tokens)\n",
        "\n",
        "# Print the statistical POS tags\n",
        "word_dict = {word: tag for word, tag in rule_based_tags}\n",
        "print(word_dict)\n",
        "\n",
        "# {'Happiness': 'NOUN', 'can': 'VERB', 'be': 'VERB', 'found': 'VERB', ',': 'PUNC', 'even': 'ADV', 'in': 'ADP', 'the': 'DET', 'darkest': 'ADJ', 'of': 'ADP', 'times': 'NOUN', 'if': 'SCONJ', 'one': 'PRON', 'only': 'ADV', 'remembers': 'VERB', 'to': 'PART', 'turn': 'VERB', 'on': 'ADP', 'light': 'NOUN', '.': 'PUNC'}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0hdrDv1U8Hq",
        "outputId": "a4df4c82-5e8f-4c37-9e1d-a7beab602884"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Happiness': 'NOUN', 'can': 'VERB', 'be': 'VERB', 'found': 'VERB', ',': 'PUNC', 'even': 'ADV', 'in': 'ADP', 'the': 'DET', 'darkest': 'ADJ', 'of': 'ADP', 'times': 'NOUN', 'if': 'SCONJ', 'one': 'PRON', 'only': 'ADV', 'remembers': 'VERB', 'to': 'PART', 'turn': 'VERB', 'on': 'ADP', 'light': 'NOUN', '.': 'PUNC'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Spacy Demo</h2>"
      ],
      "metadata": {
        "id": "Fb1GHLSojlYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import pprint\n",
        "\n",
        "# Load the SpaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Example sentence\n",
        "sentence = \"Happiness can be found, even in the darkest of times, if one only remembers to turn on the light.\"\n",
        "\n",
        "# Process the sentence\n",
        "doc = nlp(sentence)\n",
        "\n",
        "print(\" | \".join(f\"{token.text}: {token.pos_} ({token.tag_})\" for token in doc))"
      ],
      "metadata": {
        "id": "KefdtVMgjoKl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea943ef0-7a51-46d5-f34e-c88984983728"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Happiness: NOUN (NN) | can: AUX (MD) | be: AUX (VB) | found: VERB (VBN) | ,: PUNCT (,) | even: ADV (RB) | in: ADP (IN) | the: DET (DT) | darkest: NOUN (NN) | of: ADP (IN) | times: NOUN (NNS) | ,: PUNCT (,) | if: SCONJ (IN) | one: NUM (CD) | only: ADV (RB) | remembers: VERB (VBZ) | to: PART (TO) | turn: VERB (VB) | on: ADP (IN) | the: DET (DT) | light: NOUN (NN) | .: PUNCT (.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Bert Based</h2>"
      ],
      "metadata": {
        "id": "zt0GpjQzaSON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch transfomers"
      ],
      "metadata": {
        "id": "dovZsP6tag5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForTokenClassification\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load a pre-trained BERT model for token classification (fine-tuned for POS tagging)\n",
        "tokenizer = BertTokenizer.from_pretrained(\"vblagoje/bert-english-uncased-finetuned-pos\")\n",
        "model = BertForTokenClassification.from_pretrained(\"vblagoje/bert-english-uncased-finetuned-pos\")\n",
        "\n",
        "# Create a pipeline for token classification (POS tagging)\n",
        "nlp = pipeline(\"token-classification\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
        "\n",
        "# Example sentence\n",
        "sentence = \"Happiness can be found, even in the darkest of times, if one only remembers to turn on the light.\"\n",
        "\n",
        "# Perform POS tagging\n",
        "bert_tags = nlp(sentence)\n",
        "\n",
        "# Perform POS tagging and store in the dictionary\n",
        "pos_dict = {word['word']: word['entity_group'] for word in bert_tags}\n",
        "\n",
        "pos_sentence = ', '.join([f\"{word}: {tag}\" for word, tag in pos_dict.items()])\n",
        "print(f\"POS Tags: {pos_sentence}\")\n",
        "# POS Tags: Happiness: NOUN, can: AUX, be: AUX, found: VERB, , : PUNCT, even: ADV, in: ADP, the: DET, darkest: ADJ, of: ADP, times: NOUN, , : PUNCT, if: SCONJ, one: PRON, only: ADV, remembers: VERB, to: PART, turn: VERB, on: ADP, the: DET, light: NOUN, . : PUNCT\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_FfzHGdaVou",
        "outputId": "479ef384-aebb-4404-9ce6-2d995fa2d249"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at vblagoje/bert-english-uncased-finetuned-pos were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POS Tags: happiness: NOUN, can be: AUX, found: VERB, ,: PUNCT, even: ADV, in: ADP, the: DET, darkest: ADJ, of: ADP, times: NOUN, if: SCONJ, one: PRON, only: ADV, remembers: VERB, to: PART, turn: VERB, on: ADP, light: NOUN, .: PUNCT\n"
          ]
        }
      ]
    }
  ]
}